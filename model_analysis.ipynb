{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Model Results\n",
    "\n",
    "This notebook analyzes the output of the GMRF model, loading posterior samples to visualize probabilities and model parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import functools\n",
    "from dataloader import load_data\n",
    "from knn_utils import load_condition_knn\n",
    "\n",
    "# --- Global Context and Caching ---\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def get_global_condition_info():\n",
    "    \"\"\"Loads the full list of conditions and their KNN graph.\"\"\"\n",
    "    print(\"Loading global condition info (condition list and KNN)...\")\n",
    "    _, _, full_condition_list = load_data(batch_size=None) # Load all data to get the full list\n",
    "    condition_knn = load_condition_knn()\n",
    "    \n",
    "    # Create a mapping from condition name to its global index\n",
    "    condition_to_idx = {name: i for i, name in enumerate(full_condition_list)}\n",
    "    \n",
    "    print(\"Global condition info loaded.\")\n",
    "    return full_condition_list, condition_knn['indices'], condition_to_idx\n",
    "\n",
    "_reconstituted_draws_cache = {}\n",
    "\n",
    "# --- Main Loading and Interpolation Logic ---\n",
    "\n",
    "def _get_shard_specific_conditions(shard_dir):\n",
    "    \"\"\"\n",
    "    Placeholder: This function would ideally determine the specific conditions\n",
    "    present in a given shard. For now, we assume the number of columns in Lambda\n",
    "    corresponds to a slice of the global condition list.\n",
    "    \"\"\"\n",
    "    # This is a simplification. A more robust solution would save condition metadata in each shard.\n",
    "    samples = np.load(os.path.join(shard_dir, 'mcmc_samples.npy'), allow_pickle=True).item()\n",
    "    num_conditions_in_shard = samples['Lambda'].shape[2]\n",
    "    full_list, _, _ = get_global_condition_info()\n",
    "    return full_list[:num_conditions_in_shard]\n",
    "\n",
    "def _interpolate_missing_lambdas(lambda_draws, knn_indices, condition_to_idx):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the Lambda draws using nearest-neighbor interpolation.\n",
    "    \"\"\"\n",
    "    print(\"Performing nearest-neighbor interpolation for missing Lambda values...\")\n",
    "    num_draws, num_patients, num_conditions = lambda_draws.shape\n",
    "    \n",
    "    # Convert to numpy for nan-aware indexing and assignment\n",
    "    lambda_draws_np = np.asarray(lambda_draws)\n",
    "    \n",
    "    # Find all patient/condition pairs that are missing\n",
    "    missing_indices = np.argwhere(np.isnan(lambda_draws_np[0, :, :]))\n",
    "\n",
    "    for pat_idx, cond_idx in tqdm(missing_indices, desc=\"Interpolating\"):\n",
    "        # Find nearest neighbors for this condition\n",
    "        neighbor_g_indices = knn_indices[cond_idx, :]\n",
    "        \n",
    "        # Find the first neighbor that has a valid value for this patient\n",
    "        for neighbor_idx in neighbor_g_indices:\n",
    "            if not np.isnan(lambda_draws_np[0, pat_idx, neighbor_idx]):\n",
    "                # Found a valid neighbor, use its value for all draws for this patient\n",
    "                lambda_draws_np[:, pat_idx, cond_idx] = lambda_draws_np[:, pat_idx, neighbor_idx]\n",
    "                break\n",
    "    \n",
    "    print(\"Interpolation complete.\")\n",
    "    return jnp.asarray(lambda_draws_np)\n",
    "\n",
    "def load_reconstituted_lambda_draws(base_dir: str = 'Res/'):\n",
    "    \"\"\"\n",
    "    Loads Lambda draws from shards, pads them to a common shape, concatenates,\n",
    "    and then uses nearest-neighbor interpolation to fill missing values.\n",
    "    \"\"\"\n",
    "    cache_key = 'lambda_draws_interpolated'\n",
    "    if cache_key in _reconstituted_draws_cache:\n",
    "        print(\"Returning cached reconstituted Lambda draws.\")\n",
    "        return _reconstituted_draws_cache[cache_key]\n",
    "\n",
    "    print(\"Loading, padding, and interpolating Lambda draws from shards...\")\n",
    "    full_condition_list, knn_indices, condition_to_idx = get_global_condition_info()\n",
    "    C_full = len(full_condition_list)\n",
    "    \n",
    "    shard_dirs = sorted(glob.glob(os.path.join(base_dir, 'gmrf_*_shard_*')))\n",
    "    if not shard_dirs:\n",
    "        raise FileNotFoundError(f\"No 'gmrf_*' shard directories found in '{base_dir}'.\")\n",
    "\n",
    "    # Determine minimum number of draws across all shards first\n",
    "    shard_samples_info = [np.load(os.path.join(d, 'mcmc_samples.npy'), allow_pickle=True).item() for d in shard_dirs]\n",
    "    min_draws = min(s['Lambda'].shape[0] for s in shard_samples_info)\n",
    "    print(f\"Found {len(shard_dirs)} shards. Using {min_draws} draws from each.\")\n",
    "\n",
    "    padded_shards = []\n",
    "    for shard_dir, shard_samples in zip(shard_dirs, shard_samples_info):\n",
    "        lambda_shard = shard_samples['Lambda'][:min_draws, :, :]\n",
    "        S, I_shard, C_shard = lambda_shard.shape\n",
    "        \n",
    "        # This is the crucial simplification: we assume the shard's conditions\n",
    "        # are the first C_shard conditions of the global list.\n",
    "        shard_conditions = full_condition_list[:C_shard]\n",
    "        \n",
    "        # Create a full-size NaN array and fill it\n",
    "        padded_lambda = np.full((S, I_shard, C_full), np.nan)\n",
    "        for c_idx_shard, cond_name in enumerate(shard_conditions):\n",
    "            c_idx_global = condition_to_idx[cond_name]\n",
    "            padded_lambda[:, :, c_idx_global] = lambda_shard[:, :, c_idx_shard]\n",
    "        \n",
    "        padded_shards.append(padded_lambda)\n",
    "\n",
    "    # Concatenate along the patient axis\n",
    "    reconstituted_padded = np.concatenate(padded_shards, axis=1)\n",
    "    \n",
    "    # Interpolate NaN values\n",
    "    reconstituted_final = _interpolate_missing_lambdas(reconstituted_padded, knn_indices, condition_to_idx)\n",
    "    \n",
    "    _reconstituted_draws_cache[cache_key] = reconstituted_final\n",
    "    print(\"Reconstitution and interpolation complete.\")\n",
    "    \n",
    "    return reconstituted_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and reconstituting Lambda draws from shards...\n",
      "Found 13 shards. Using 4000 draws from each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8333944bb24d6bad63c97f09e6fd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Concatenating draws:   0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot concatenate arrays with shapes that differ in dimensions other than the one being concatenated: concatenating along dimension 0 for shapes (499, 43), (499, 41), (499, 42), (499, 39), (499, 39), (499, 39), (499, 38), (499, 38), (499, 37), (499, 36), (499, 35), (499, 37), (491, 42).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1.0\u001b[39m / (\u001b[32m1.0\u001b[39m + jnp.exp(-x))\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Load the reconstituted Lambda draws\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# This function handles the logic of finding shards and concatenating Lambdas\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m lambda_draws = \u001b[43mload_reconstituted_lambda_draws\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Compute posterior mean probabilities\u001b[39;00m\n\u001b[32m     14\u001b[39m P_mean = _sigmoid(jnp.mean(lambda_draws, axis=\u001b[32m0\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mload_reconstituted_lambda_draws\u001b[39m\u001b[34m(base_dir)\u001b[39m\n\u001b[32m     47\u001b[39m     lambda_slices_for_draw = [jnp.asarray(s[\u001b[33m'\u001b[39m\u001b[33mLambda\u001b[39m\u001b[33m'\u001b[39m][i]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m shard_samples]\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# Concatenate along the patient axis (axis 0 for a single draw)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     full_lambda_draw = \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_slices_for_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     all_lambda_draws.append(full_lambda_draw)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Stack all the full draws to create the final posterior sample matrix\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/numpy/lax_numpy.py:4648\u001b[39m, in \u001b[36mconcatenate\u001b[39m\u001b[34m(arrays, axis, dtype)\u001b[39m\n\u001b[32m   4646\u001b[39m k = \u001b[32m16\u001b[39m\n\u001b[32m   4647\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arrays_out) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4648\u001b[39m   arrays_out = [\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4649\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(arrays_out), k)]\n\u001b[32m   4650\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_out[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/lax/lax.py:2000\u001b[39m, in \u001b[36mconcatenate\u001b[39m\u001b[34m(operands, dimension)\u001b[39m\n\u001b[32m   1998\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op\n\u001b[32m   1999\u001b[39m operands = core.standard_insert_pvary(*operands)\n\u001b[32m-> \u001b[39m\u001b[32m2000\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/core.py:496\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    495\u001b[39m   args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/core.py:512\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    510\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    514\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/core.py:517\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/core.py:1017\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1015\u001b[39m args = \u001b[38;5;28mmap\u001b[39m(full_lower, args)\n\u001b[32m   1016\u001b[39m check_eval_args(args)\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/dispatch.py:89\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     87\u001b[39m prev = lib.jax_jit.swap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     91\u001b[39m   lib.jax_jit.swap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[31m[... skipping hidden 23 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/polypharm/lib/python3.13/site-packages/jax/_src/lax/lax.py:6655\u001b[39m, in \u001b[36m_concatenate_shape_rule\u001b[39m\u001b[34m(*operands, **kwargs)\u001b[39m\n\u001b[32m   6651\u001b[39m   msg = (\u001b[33m\"\u001b[39m\u001b[33mCannot concatenate arrays with shapes that differ in dimensions \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6652\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mother than the one being concatenated: concatenating along \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6653\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mdimension \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m for shapes \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6654\u001b[39m   shapes = [operand.shape \u001b[38;5;28;01mfor\u001b[39;00m operand \u001b[38;5;129;01min\u001b[39;00m operands]\n\u001b[32m-> \u001b[39m\u001b[32m6655\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(dimension, \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, shapes))))\n\u001b[32m   6657\u001b[39m concat_size = \u001b[38;5;28msum\u001b[39m(o.shape[dimension] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m operands)\n\u001b[32m   6658\u001b[39m ex_shape = operands[\u001b[32m0\u001b[39m].shape\n",
      "\u001b[31mTypeError\u001b[39m: Cannot concatenate arrays with shapes that differ in dimensions other than the one being concatenated: concatenating along dimension 0 for shapes (499, 43), (499, 41), (499, 42), (499, 39), (499, 39), (499, 39), (499, 38), (499, 38), (499, 37), (499, 36), (499, 35), (499, 37), (491, 42)."
     ]
    }
   ],
   "source": [
    "# Heatmap of posterior mean probabilities\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def _sigmoid(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    return 1.0 / (1.0 + jnp.exp(-x))\n",
    "\n",
    "# Load the reconstituted Lambda draws\n",
    "# This function handles the logic of finding shards and concatenating Lambdas\n",
    "lambda_draws = load_reconstituted_lambda_draws()\n",
    "\n",
    "# Compute posterior mean probabilities\n",
    "P_mean = _sigmoid(jnp.mean(lambda_draws, axis=0))\n",
    "print(f\"Computed posterior mean probability matrix with shape: {P_mean.shape}\")\n",
    "\n",
    "# Plot heatmap in original order\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(np.asarray(P_mean), cmap='viridis', vmin=0.0, vmax=1.0, cbar=True,\n",
    "            xticklabels=False, yticklabels=False)\n",
    "plt.title('Posterior Mean Probability (Reconstituted from Shards)')\n",
    "plt.xlabel('Diseases')\n",
    "plt.ylabel('Patients')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of posterior standard deviation of probabilities\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Use the reconstituted Lambda draws from the previous cell\n",
    "# This avoids re-loading the data if the cache is populated\n",
    "if 'lambda_draws' not in locals():\n",
    "    lambda_draws = load_reconstituted_lambda_draws()\n",
    "\n",
    "# Compute probabilities for each draw, then find the standard deviation\n",
    "p_draws = _sigmoid(lambda_draws)\n",
    "P_std = jnp.std(p_draws, axis=0)\n",
    "print(f\"Loaded probability draws: {p_draws.shape}; std matrix shape: {P_std.shape}\")\n",
    "\n",
    "# Plot heatmap of posterior std\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(np.asarray(P_std), cmap='magma', vmin=0.0, vmax=0.5, cbar=True,\n",
    "            xticklabels=False, yticklabels=False)\n",
    "plt.title('Posterior Std Dev of Probability (Reconstituted from Shards)')\n",
    "plt.xlabel('Diseases')\n",
    "plt.ylabel('Patients')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix and Classification Report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from dataloader import load_data\n",
    "\n",
    "# Load ground truth from dataloader and align with predicted probabilities\n",
    "\n",
    "def load_ground_truth_from_dataloader() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load A from dataloader, convert to 2D patient-by-condition binary matrix in {0,1}.\n",
    "    \"\"\"\n",
    "    A, _, _ = load_data()\n",
    "    A_2d = A[:, :, 0] if A.ndim == 3 else A\n",
    "    if np.min(A_2d) < 0:\n",
    "        A_2d = (A_2d + 1) / 2\n",
    "    return A_2d.astype(np.int32)\n",
    "\n",
    "# Use the P_mean computed in the previous cell\n",
    "if 'P_mean' not in locals():\n",
    "     raise NameError(\"'P_mean' not defined. Please run the cell that computes the posterior mean probability first.\")\n",
    "\n",
    "A_true_full = load_ground_truth_from_dataloader()\n",
    "A_true = A_true_full[:P_mean.shape[0], :P_mean.shape[1]]\n",
    "\n",
    "# Binarize predictions at 0.5 threshold\n",
    "A_pred = (P_mean >= 0.5).astype(np.int32)\n",
    "\n",
    "# Flatten for confusion matrix computation\n",
    "y_true = A_true.flatten()\n",
    "y_pred = np.asarray(A_pred).flatten()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Optionally, print classification report for more detail\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of Beta Parameters from Combined Results\n",
    "import os\n",
    "import glob\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_beta_samples_from_combined(base_dir: str = 'Res/'):\n",
    "    \"\"\"\n",
    "    Loads beta parameter samples from the latest combined results directory.\n",
    "    It reconstructs 'beta_cond' if it is not directly available.\n",
    "    \"\"\"\n",
    "    combined_dirs = sorted(glob.glob(os.path.join(base_dir, 'sharded_hierarchical_gp_*')))\n",
    "    if not combined_dirs:\n",
    "        raise FileNotFoundError(f\"No 'sharded_hierarchical_gp_*' directories found in '{base_dir}'.\")\n",
    "    \n",
    "    latest_combined_dir = combined_dirs[-1]\n",
    "    print(f\"Loading beta parameters from: {latest_combined_dir}\")\n",
    "    \n",
    "    payload = np.load(os.path.join(latest_combined_dir, 'combined_post_samples.npy'), allow_pickle=True).item()\n",
    "    \n",
    "    if 'beta_cond' in payload:\n",
    "        beta_samples = jnp.asarray(payload['beta_cond'])\n",
    "    elif 'tau' in payload and 'lambdas' in payload:\n",
    "        tau = jnp.asarray(payload['tau']).reshape(-1, 1)\n",
    "        lambdas = jnp.asarray(payload['lambdas'])\n",
    "        beta_samples = tau * lambdas\n",
    "    else:\n",
    "        raise KeyError(\"'beta_cond' or ('tau' and 'lambdas') not found in combined results.\")\n",
    "        \n",
    "    return beta_samples\n",
    "\n",
    "# Load the beta samples\n",
    "try:\n",
    "    beta_samples = load_beta_samples_from_combined()\n",
    "    \n",
    "    num_betas = beta_samples.shape[1]\n",
    "\n",
    "    # Compute posterior mean and 95% credible interval\n",
    "    beta_means = jnp.mean(beta_samples, axis=0)\n",
    "    beta_lower, beta_upper = jnp.percentile(beta_samples, jnp.array([2.5, 97.5]), axis=0)\n",
    "\n",
    "    # Compute error bars\n",
    "    yerr = jnp.vstack([beta_means - beta_lower, beta_upper - beta_means])\n",
    "\n",
    "    # Plot posterior means with error bars\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.errorbar(np.arange(num_betas), np.asarray(beta_means), yerr=np.asarray(yerr), \n",
    "                 capsize=3, capthick=1, fmt='o', markersize=4, \n",
    "                 color='blue', ecolor='gray', alpha=0.7)\n",
    "    plt.axhline(y=0, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    plt.xlabel('Beta Index (Condition)')\n",
    "    plt.ylabel('Posterior Mean')\n",
    "    plt.title('Posterior Means of Beta_Cond with 95% Credible Intervals')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary of Beta_Cond Parameters:\")\n",
    "    print(f\"Number of conditions: {num_betas}\")\n",
    "    print(f\"Mean of all beta means: {jnp.mean(beta_means):.4f}\")\n",
    "    \n",
    "    excludes_zero = jnp.sum((beta_lower > 0) | (beta_upper < 0))\n",
    "    print(f\"Number of betas with 95% CI excluding zero: {excludes_zero}\")\n",
    "\n",
    "except (FileNotFoundError, KeyError) as e:\n",
    "    print(f\"Skipping beta analysis: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polypharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
