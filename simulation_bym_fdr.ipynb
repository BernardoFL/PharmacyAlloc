{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BYM Prediction-Based FDR Simulation\n",
        "\n",
        "This notebook runs a simulation study to estimate prediction-based False Discovery Rate (FDR) for a BYM model. In each simulation, we:\n",
        "- Generate ground-truth patient and condition effects\n",
        "- Mask a random fraction of observations\n",
        "- Fit a BYM model on masked data (handling NaNs)\n",
        "- Predict masked entries and compute FDR = FP / (FP + TP)\n",
        "\n",
        "The final section summarizes the distribution of FDR across runs and visualizes it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Setup and Parameters\n",
        "\n",
        "Imports core libraries (JAX, NumPy, NumPyro, SciPy/sklearn, Matplotlib) and defines:\n",
        "- Simulation controls: number of simulations `N_sims`, patients `I`, conditions `C`, k-NN parameter `k`, masking fraction.\n",
        "- Ground-truth parameters for data generation (`tau_s_true`, `tau_u_true`, `sigma_delta_true`).\n",
        "- Sampler configuration (`num_warmup`, `num_samples`, `num_chains`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulation parameters set: {'N_sims': 100, 'I': 200, 'C': 50, 'k': 10, 'masking_fraction': 0.2, 'tau_s_true': 1.5, 'tau_u_true': 2.0, 'sigma_delta_true': 0.75, 'num_warmup': 500, 'num_samples': 500, 'num_chains': 1}\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Parameters\n",
        "import os\n",
        "import time\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import MCMC, NUTS\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Simulation parameters ---\n",
        "N_sims = 100  # number of simulation repetitions\n",
        "I = 200       # number of patients\n",
        "C = 50        # number of conditions\n",
        "k = 10        # k for k-NN graph\n",
        "masking_fraction = 0.2  # fraction of grid entries to mask\n",
        "\n",
        "# --- True parameters for data generation ---\n",
        "tau_s_true = 1.5       # structured precision\n",
        "tau_u_true = 2.0       # unstructured precision\n",
        "sigma_delta_true = 0.75  # std dev for condition effects\n",
        "\n",
        "# --- Sampler parameters (exposed for runtime control) ---\n",
        "num_warmup = 500\n",
        "num_samples = 500\n",
        "num_chains = 1\n",
        "\n",
        "print(\"Simulation parameters set:\", {\n",
        "    'N_sims': N_sims,\n",
        "    'I': I,\n",
        "    'C': C,\n",
        "    'k': k,\n",
        "    'masking_fraction': masking_fraction,\n",
        "    'tau_s_true': tau_s_true,\n",
        "    'tau_u_true': tau_u_true,\n",
        "    'sigma_delta_true': sigma_delta_true,\n",
        "    'num_warmup': num_warmup,\n",
        "    'num_samples': num_samples,\n",
        "    'num_chains': num_chains,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Helper Functions\n",
        "\n",
        "- `get_laplacian_from_locs`: builds the patient k-NN graph and returns the graph Laplacian `L = D - W` as a JAX array.\n",
        "- `bym_model`: a NumPyro BYM model with:\n",
        "  - Structured component via `numpyro.factor` using the Laplacian energy `phi^T L phi` scaled by `tau_s`.\n",
        "  - Unstructured component via `||phi||^2` scaled by `tau_u`.\n",
        "  - Condition effects `delta` with prior scale `sigma_delta`.\n",
        "  - Likelihood `Bernoulli(logits=phi[:,None]+delta[None,:])` masked to ignore `NaN` entries in `y`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Main Simulation Loop\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + jnp.exp(-x))\n",
        "\n",
        "fdr_results = []\n",
        "key = jax.random.PRNGKey(0)\n",
        "\n",
        "for sim in range(N_sims):\n",
        "    t0 = time.time()\n",
        "    # --- Generate Ground Truth Data ---\n",
        "    # Random 2D locations in unit square\n",
        "    key, k_locs = jax.random.split(key)\n",
        "    locations = jax.random.uniform(k_locs, shape=(I, 2), minval=0.0, maxval=1.0)\n",
        "    locations_np = np.array(locations)\n",
        "\n",
        "    # Build true patient Laplacian\n",
        "    L_pat_true = get_laplacian_from_locs(locations_np, k)\n",
        "\n",
        "    # Construct true precision Q_true = tau_s_true * L_pat_true + tau_u_true * I\n",
        "    Q_true = tau_s_true * L_pat_true + (tau_u_true + 1e-5) * jnp.eye(I)\n",
        "\n",
        "    # Sample phi_true ~ N(0, Q_true^{-1}) via Cholesky of Q_true\n",
        "    # Solve Q_true^{-1/2} * z, with z ~ N(0, I)\n",
        "    # Use symmetric PD assumption with jitter\n",
        "    L_chol = jnp.linalg.cholesky(Q_true)\n",
        "    key, k_z = jax.random.split(key)\n",
        "    z = jax.random.normal(k_z, shape=(I,))\n",
        "    # Solve L_chol x = z then L_chol^T phi = x => phi = (L_chol^{-T}) (L_chol^{-1}) z\n",
        "    x = jax.scipy.linalg.solve_triangular(L_chol, z, lower=True)\n",
        "    phi_true = jax.scipy.linalg.solve_triangular(L_chol.T, x, lower=False)\n",
        "\n",
        "    # Condition effects\n",
        "    key, k_delta = jax.random.split(key)\n",
        "    delta_true = jax.random.normal(k_delta, shape=(C,)) * sigma_delta_true\n",
        "\n",
        "    # Linear predictor and probabilities\n",
        "    Lambda_true = phi_true[:, None] + delta_true[None, :]\n",
        "    p_true = sigmoid(Lambda_true)\n",
        "\n",
        "    # Sample binary outcomes\n",
        "    key, k_y = jax.random.split(key)\n",
        "    y_true = jax.random.bernoulli(k_y, p=p_true).astype(jnp.float32)\n",
        "\n",
        "    # --- Masked Training Data ---\n",
        "    key, k_mask = jax.random.split(key)\n",
        "    total_entries = I * C\n",
        "    num_mask = int(masking_fraction * total_entries)\n",
        "    flat_indices = jax.random.choice(k_mask, total_entries, shape=(num_mask,), replace=False)\n",
        "    mask_rows = (flat_indices // C).astype(int)\n",
        "    mask_cols = (flat_indices % C).astype(int)\n",
        "\n",
        "    y_train = y_true.copy()\n",
        "    y_train = y_train.at[mask_rows, mask_cols].set(jnp.nan)\n",
        "\n",
        "    true_mask_values = y_true[mask_rows, mask_cols]\n",
        "\n",
        "    # --- Fit BYM Model ---\n",
        "    def model():\n",
        "        return bym_model(L_pat_true, y_train, I, C)\n",
        "\n",
        "    nuts = NUTS(model)\n",
        "    mcmc = MCMC(nuts, num_warmup=num_warmup, num_samples=num_samples, num_chains=num_chains, progress_bar=False)\n",
        "    mcmc.run(key)\n",
        "    samples = mcmc.get_samples()\n",
        "\n",
        "    # --- Predictions for Masked Entries ---\n",
        "    phi_mean = samples['phi'].mean(axis=0)\n",
        "    delta_mean = samples['delta'].mean(axis=0)\n",
        "    Lambda_pred = phi_mean[:, None] + delta_mean[None, :]\n",
        "    p_pred = sigmoid(Lambda_pred)\n",
        "\n",
        "    pred_mask_probs = p_pred[mask_rows, mask_cols]\n",
        "\n",
        "    # Discoveries: p > 0.5\n",
        "    discoveries = pred_mask_probs > 0.5\n",
        "\n",
        "    # Compute FP and TP\n",
        "    tp = jnp.sum((discoveries) & (true_mask_values == 1))\n",
        "    fp = jnp.sum((discoveries) & (true_mask_values == 0))\n",
        "\n",
        "    denom = tp + fp\n",
        "    fdr = jnp.where(denom > 0, fp / denom, 0.0)\n",
        "    fdr_results.append(float(fdr))\n",
        "\n",
        "    t1 = time.time()\n",
        "    print(f\"Sim {sim+1}/{N_sims}: FDR={float(fdr):.3f} (elapsed {t1 - t0:.1f}s, masked={num_mask})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Final Analysis and Visualization\n",
        "\n",
        "fdr_arr = np.asarray(fdr_results, dtype=float)\n",
        "mean_fdr = float(np.nanmean(fdr_arr)) if fdr_arr.size else float('nan')\n",
        "std_fdr = float(np.nanstd(fdr_arr)) if fdr_arr.size else float('nan')\n",
        "\n",
        "print(f\"Prediction-based FDR across {len(fdr_arr)} simulations:\")\n",
        "print(f\"  Mean: {mean_fdr:.4f}\")\n",
        "print(f\"  Std:  {std_fdr:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.hist(fdr_arr, bins=20, alpha=0.75, color='steelblue', edgecolor='white')\n",
        "plt.axvline(mean_fdr, color='red', linestyle='--', linewidth=2, label=f\"Mean = {mean_fdr:.3f}\")\n",
        "plt.xlabel('FDR')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Prediction-Based FDR')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Interpretation\n",
        "\n",
        "This section aggregates the FDR across all simulation runs and visualizes its distribution. A lower mean FDR indicates fewer false discoveries among positive predictions on masked entries. The histogram helps assess variability across runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Helper Functions\n",
        "from numpyro import handlers\n",
        "\n",
        "\n",
        "def get_laplacian_from_locs(locations: np.ndarray, k: int) -> jnp.ndarray:\n",
        "    \"\"\"\n",
        "    Build an (I x I) graph Laplacian from 2D locations using k-NN adjacency.\n",
        "    Returns a dense JAX array L = D - W.\n",
        "    \"\"\"\n",
        "    I = locations.shape[0]\n",
        "    # k-NN adjacency (exclude self-loops by setting include_self=False)\n",
        "    A = kneighbors_graph(locations, n_neighbors=k, mode='connectivity', include_self=False)\n",
        "    # Symmetrize\n",
        "    W = (A + A.T).astype(bool).astype(np.float32)\n",
        "    # Degree and Laplacian\n",
        "    degrees = np.asarray(W.sum(axis=1)).ravel()\n",
        "    D = np.diag(degrees)\n",
        "    L = D - W.toarray()\n",
        "    return jnp.asarray(L, dtype=jnp.float32)\n",
        "\n",
        "\n",
        "def bym_model(L_pat: jnp.ndarray, y: jnp.ndarray, I: int, C: int):\n",
        "    \"\"\"\n",
        "    NumPyro BYM model with NaN-masked observations.\n",
        "    L_pat: (I x I) dense Laplacian\n",
        "    y: (I x C) with NaNs indicating masked entries\n",
        "    \"\"\"\n",
        "    # Hyperpriors\n",
        "    tau_s = numpyro.sample(\"tau_s\", dist.HalfCauchy(2.0))\n",
        "    tau_u = numpyro.sample(\"tau_u\", dist.HalfCauchy(2.0))\n",
        "    sigma_delta = numpyro.sample(\"sigma_delta\", dist.HalfCauchy(1.0))\n",
        "\n",
        "    # Latents\n",
        "    delta = numpyro.sample(\"delta\", dist.Normal(0, sigma_delta).expand([C]))\n",
        "    phi = numpyro.sample(\"phi\", dist.Normal(0, 1.0).expand([I]))\n",
        "\n",
        "    # Structured (ICAR-like) energy and unstructured energy\n",
        "    U_structured = tau_s * (phi @ (L_pat @ phi))\n",
        "    numpyro.factor(\"structured_effect\", -0.5 * U_structured)\n",
        "\n",
        "    U_unstructured = tau_u * jnp.sum(phi ** 2)\n",
        "    numpyro.factor(\"unstructured_effect\", -0.5 * U_unstructured)\n",
        "\n",
        "    # Linear predictor\n",
        "    Lambda = phi[:, None] + delta[None, :]\n",
        "\n",
        "    # Likelihood with masking (mask True for observed entries)\n",
        "    obs_mask = ~jnp.isnan(y)\n",
        "    with handlers.mask(mask=obs_mask):\n",
        "        numpyro.sample(\"obs\", dist.Bernoulli(logits=Lambda), obs=y)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "polypharm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
